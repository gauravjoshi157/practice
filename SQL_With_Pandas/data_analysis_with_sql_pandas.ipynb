{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Pandas and SQL Integration\n",
    "\n",
    "Pandas’ `read_sql` and `to_sql` Functions\n",
    "1. `read_sql` Function\n",
    "\n",
    "The `read_sql` function in Pandas is used to execute SQL queries and load the results into a Pandas DataFrame. It is a powerful tool for extracting data from SQL databases and integrating it into your data analysis workflow. Here’s a detailed breakdown of its usage:\n",
    "\n",
    "Syntax: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.read_sql(sql, con, index_col=None, coerce_float=True, params=None, chunksize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- __Parameters:__\n",
    "    - `sql`: The SQL query or name of the table to read from. This can be a SQL query string or a table name.\n",
    "\n",
    "    - `con`: A database connection object or SQLAlchemy engine instance. This defines the database connection used to execute the SQL query.\n",
    "\n",
    "    - `index_col`: (Optional) Column to set as the index of the DataFrame. If not specified, a default integer index is used.\n",
    "\n",
    "    - `coerce_float`: (Optional) If True, attempts to convert values to float.\n",
    "\n",
    "    - `params`: (Optional) Parameters to pass to the SQL query, used for parameterized queries.\n",
    "\n",
    "    - `chunksize`: (Optional) If specified, the function will return an iterator where each chunk is a DataFrame with up to chunksize rows.\n",
    "\n",
    "__Example:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     name  age   department   salary department_id\n",
      "0   1    Alice   30           HR  50000.0          None\n",
      "1   2      Bob   25  Engineering  60000.0          None\n",
      "2   3  Charlie   35    Marketing  55000.0          None\n",
      "3   4    David   40        Sales  70000.0          None\n",
      "4   5      Eve   28  Engineering  65000.0          None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create a database connection\n",
    "engine = create_engine('sqlite:///mydatabase.db')\n",
    "\n",
    "# SQL query\n",
    "query = 'SELECT * FROM employee'\n",
    "\n",
    "# Read data from the database\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `to_sql`Function\n",
    "\n",
    "The `to_sql` function allows you to write a Pandas DataFrame to a SQL database, either creating a new table or appending to an existing one. This function facilitates data persistence and integration with databases. Here’s a detailed breakdown:\n",
    "\n",
    "- __Syntex:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataframe.to_sql(name, con, schema = none, if_exists = 'fail', index = True, index_label = None, chunksize = None, dtype = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parameters:\n",
    "    - `name:` The name of the table to write to. If the table does not exist, it will be created.\n",
    "\n",
    "    - `con:` A database connection object or SQLAlchemy engine instance. Defines the database connection used to write the DataFrame.\n",
    "\n",
    "    - `schema:` (Optional) The database schema to write to. Default is None.\n",
    "    \n",
    "    - `if_exists:` (Optional) Specifies what to do if the table already exists. Options include:\n",
    "        - `'fail':` (default) Raise a ValueError.\n",
    "\n",
    "        - `'replace':` Drop the table before inserting new values.\n",
    "\n",
    "        - `'append':` Append data to the existing table.\n",
    "\n",
    "    - `index:` (Optional) Whether to write the DataFrame index as a column. Default is True.\n",
    "\n",
    "    - `index_label:` (Optional) Column name to use for the index column. Default is None.\n",
    "\n",
    "    - `chunksize:` (Optional) Number of rows to write at a time. Useful for large DataFrames.\n",
    "\n",
    "    - `dtype:` (Optional) Data type to force for columns. Can be a dictionary mapping column names to data types.\n",
    "    \n",
    "__Example:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create a database connection\n",
    "engine = create_engine('sqlite:///mydatabase.db')\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['John Doe', 'Jane Smith'],\n",
    "    'age': [30, 25]\n",
    "})\n",
    "\n",
    "# Write DataFrame to SQL table\n",
    "df.to_sql('people', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data written to database successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Additional Functions and Methods Related to SQL Integration__\n",
    "\n",
    "- `SQLAlchemy.create_engine`\n",
    "    - Used to create a SQLAlchemy engine, which is required for connecting to various types of SQL databases. It provides a unified interface for interacting with different database systems.\n",
    "- __Syntax:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('dialect+driver://username:password@host:port/datanase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Example:__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///mydatabase.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `DataFrame.query`\n",
    "    - Allow you t oquery a DataFrame using a SQL-like syntex. Useful For filtering and selecting data within a DataFrame. \n",
    "\n",
    "- Syntex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.query(expr, inplace = False , **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Example__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('age>25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By understanding and utilizing these functions, you can efficiently manage data flow between SQL databases and Pandas, enabling comprehensive data analysis and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Databases with Pandas\n",
    "\n",
    "Querying databases with Pandas involves retrieving data from SQL databases and manipulating it within Pandas DataFrames. This integration allows you to perform complex data analysis by combining the power of SQL with Pandas’ data manipulation capabilities.\n",
    "\n",
    "### 1. Filtering Data\n",
    "\n",
    "Filtering data means retrieving only those rows from a table that meet certain conditions. You can either filter the data directly in the SQL query or load the data into a Pandas DataFrame and then apply filtering.\n",
    "\n",
    "- __Example:__ Filtering with SQL Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id     name  age   department   salary\n",
      "0    3  Charlie   35    Marketing  55000.0\n",
      "1    4    David   40        Sales  70000.0\n",
      "2    6    Frank   32           HR  52000.0\n",
      "3    8     Hank   45        Sales  72000.0\n",
      "4   10     Jack   38           HR  54000.0\n",
      "5   11    Kathy   31    Marketing  60000.0\n",
      "6   13     Mona   33        Sales  71000.0\n",
      "7   14     Nate   34  Engineering  64000.0\n",
      "8   15   Olivia   36           HR  53000.0\n",
      "9   17   Quincy   37    Marketing  59000.0\n",
      "10  19      Sam   41        Sales  75000.0\n",
      "11  23  Charlie   35    Marketing  55000.0\n",
      "12  24    David   40        Sales  70000.0\n",
      "13  26    Frank   32           HR  52000.0\n",
      "14  28     Hank   45        Sales  72000.0\n",
      "15  30     Jack   38           HR  54000.0\n",
      "16  31    Kathy   31    Marketing  60000.0\n",
      "17  33     Mona   33        Sales  71000.0\n",
      "18  34     Nate   34  Engineering  64000.0\n",
      "19  35   Olivia   36           HR  53000.0\n",
      "20  37   Quincy   37    Marketing  59000.0\n",
      "21  39      Sam   41        Sales  75000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Step 1: Create a database connection using SQLAlchemy's create_engine function.\n",
    "# This allows Pandas to communicate with the database.\n",
    "engine = create_engine('sqlite:///mydatabase.db')\n",
    "\n",
    "# Step 2: Write an SQL query to select all employees older than 30.\n",
    "query = 'SELECT * FROM employee WHERE age > 30'\n",
    "\n",
    "# Step 3: Execute the SQL query using pd.read_sql() to fetch the data from the database.\n",
    "# The fetched data is automatically loaded into a Pandas DataFrame.\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Step 4: Display the resulting DataFrame.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "    - `pd.read_sql(query, con=engine):` This function executes the SQL query and loads the results into a Pandas DataFrame. The `con=engine` parameter specifies the database connection.\n",
    "\n",
    "    - The DataFrame `df` now contains only book where id = 2 .\n",
    "\n",
    "__Example: Filtering with Pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id     name  age   department   salary\n",
      "0    3  Charlie   35    Marketing  55000.0\n",
      "1    4    David   40        Sales  70000.0\n",
      "2    6    Frank   32           HR  52000.0\n",
      "3    8     Hank   45        Sales  72000.0\n",
      "4   10     Jack   38           HR  54000.0\n",
      "5   11    Kathy   31    Marketing  60000.0\n",
      "6   13     Mona   33        Sales  71000.0\n",
      "7   14     Nate   34  Engineering  64000.0\n",
      "8   15   Olivia   36           HR  53000.0\n",
      "9   17   Quincy   37    Marketing  59000.0\n",
      "10  19      Sam   41        Sales  75000.0\n",
      "11  23  Charlie   35    Marketing  55000.0\n",
      "12  24    David   40        Sales  70000.0\n",
      "13  26    Frank   32           HR  52000.0\n",
      "14  28     Hank   45        Sales  72000.0\n",
      "15  30     Jack   38           HR  54000.0\n",
      "16  31    Kathy   31    Marketing  60000.0\n",
      "17  33     Mona   33        Sales  71000.0\n",
      "18  34     Nate   34  Engineering  64000.0\n",
      "19  35   Olivia   36           HR  53000.0\n",
      "20  37   Quincy   37    Marketing  59000.0\n",
      "21  39      Sam   41        Sales  75000.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Assume you have a DataFrame 'df' containing all employees' data.\n",
    "# You want to filter out employees whose age is greater than 30.\n",
    "\n",
    "# Step 2: Apply the filtering condition using Pandas' DataFrame filtering.\n",
    "filtered_df = df[df['age'] > 30]\n",
    "\n",
    "# Step 3: Display the filtered DataFrame.\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "\n",
    "    - `df['age'] > 30:` This creates a boolean mask, which is True for rows where the age is greater than 30 and False otherwise.\n",
    "\n",
    "    - `df[df['age'] > 30]:` The DataFrame is filtered based on the boolean mask, returning only the rows where the condition is True.\n",
    "    \n",
    "### 2. Sorting Data\n",
    "\n",
    "Sorting data involves arranging the rows in a DataFrame based on the values in one or more columns. Sorting can be done in SQL before the data is loaded or within Pandas after the data is loaded.\n",
    "\n",
    "- __Example: Sorting with SQL Query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id     name  age   department   salary\n",
      "0    8     Hank   45        Sales  72000.0\n",
      "1   28     Hank   45        Sales  72000.0\n",
      "2   19      Sam   41        Sales  75000.0\n",
      "3   39      Sam   41        Sales  75000.0\n",
      "4    4    David   40        Sales  70000.0\n",
      "5   24    David   40        Sales  70000.0\n",
      "6   10     Jack   38           HR  54000.0\n",
      "7   30     Jack   38           HR  54000.0\n",
      "8   17   Quincy   37    Marketing  59000.0\n",
      "9   37   Quincy   37    Marketing  59000.0\n",
      "10  15   Olivia   36           HR  53000.0\n",
      "11  35   Olivia   36           HR  53000.0\n",
      "12   3  Charlie   35    Marketing  55000.0\n",
      "13  23  Charlie   35    Marketing  55000.0\n",
      "14  14     Nate   34  Engineering  64000.0\n",
      "15  34     Nate   34  Engineering  64000.0\n",
      "16  13     Mona   33        Sales  71000.0\n",
      "17  33     Mona   33        Sales  71000.0\n",
      "18   6    Frank   32           HR  52000.0\n",
      "19  26    Frank   32           HR  52000.0\n",
      "20  11    Kathy   31    Marketing  60000.0\n",
      "21  31    Kathy   31    Marketing  60000.0\n",
      "22   1    Alice   30           HR  50000.0\n",
      "23  21    Alice   30           HR  50000.0\n",
      "24   7    Grace   29    Marketing  58000.0\n",
      "25  16     Pete   29        Sales  68000.0\n",
      "26  27    Grace   29    Marketing  58000.0\n",
      "27  36     Pete   29        Sales  68000.0\n",
      "28   5      Eve   28  Engineering  65000.0\n",
      "29  20     Tina   28           HR  56000.0\n",
      "30  25      Eve   28  Engineering  65000.0\n",
      "31  40     Tina   28           HR  56000.0\n",
      "32  12      Leo   27  Engineering  67000.0\n",
      "33  32      Leo   27  Engineering  67000.0\n",
      "34   9      Ivy   26  Engineering  63000.0\n",
      "35  29      Ivy   26  Engineering  63000.0\n",
      "36   2      Bob   25  Engineering  60000.0\n",
      "37  22      Bob   25  Engineering  60000.0\n",
      "38  18     Rita   24  Engineering  62000.0\n",
      "39  38     Rita   24  Engineering  62000.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Write an SQL query to sort the data by age in descending order.\n",
    "query = 'SELECT * FROM employee ORDER BY age DESC'\n",
    "\n",
    "# Step 2: Execute the SQL query and load the sorted data into a Pandas DataFrame.\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Step 3: Display the sorted DataFrame.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Explanation:__\n",
    "\n",
    "- `ORDER BY ade DESC`: This clause sorts the rows by the `age` column in descendind order (hidhest ade first).\n",
    "- The resultind DataFrame `df` is sorted by ade when loaded.\n",
    "\n",
    "__Example: Sortind with Pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id     name  age   department   salary\n",
      "0    8     Hank   45        Sales  72000.0\n",
      "1   28     Hank   45        Sales  72000.0\n",
      "2   19      Sam   41        Sales  75000.0\n",
      "3   39      Sam   41        Sales  75000.0\n",
      "4    4    David   40        Sales  70000.0\n",
      "5   24    David   40        Sales  70000.0\n",
      "6   10     Jack   38           HR  54000.0\n",
      "7   30     Jack   38           HR  54000.0\n",
      "8   17   Quincy   37    Marketing  59000.0\n",
      "9   37   Quincy   37    Marketing  59000.0\n",
      "11  35   Olivia   36           HR  53000.0\n",
      "10  15   Olivia   36           HR  53000.0\n",
      "12   3  Charlie   35    Marketing  55000.0\n",
      "13  23  Charlie   35    Marketing  55000.0\n",
      "14  14     Nate   34  Engineering  64000.0\n",
      "15  34     Nate   34  Engineering  64000.0\n",
      "16  13     Mona   33        Sales  71000.0\n",
      "17  33     Mona   33        Sales  71000.0\n",
      "18   6    Frank   32           HR  52000.0\n",
      "19  26    Frank   32           HR  52000.0\n",
      "21  31    Kathy   31    Marketing  60000.0\n",
      "20  11    Kathy   31    Marketing  60000.0\n",
      "22   1    Alice   30           HR  50000.0\n",
      "23  21    Alice   30           HR  50000.0\n",
      "24   7    Grace   29    Marketing  58000.0\n",
      "25  16     Pete   29        Sales  68000.0\n",
      "26  27    Grace   29    Marketing  58000.0\n",
      "27  36     Pete   29        Sales  68000.0\n",
      "30  25      Eve   28  Engineering  65000.0\n",
      "31  40     Tina   28           HR  56000.0\n",
      "29  20     Tina   28           HR  56000.0\n",
      "28   5      Eve   28  Engineering  65000.0\n",
      "32  12      Leo   27  Engineering  67000.0\n",
      "33  32      Leo   27  Engineering  67000.0\n",
      "34   9      Ivy   26  Engineering  63000.0\n",
      "35  29      Ivy   26  Engineering  63000.0\n",
      "36   2      Bob   25  Engineering  60000.0\n",
      "37  22      Bob   25  Engineering  60000.0\n",
      "38  18     Rita   24  Engineering  62000.0\n",
      "39  38     Rita   24  Engineering  62000.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Assume 'df' is a DataFrame containing employee' data.\n",
    "\n",
    "# Step 2: Use Pandas' sort_values() to sort the DataFrame by age in descending order.\n",
    "sorted_df = df.sort_values(by='age', ascending=False)\n",
    "\n",
    "# Step 3: Display the sorted DataFrame.\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "- `df.sort_values(by='age', ascending=False)`: This sorts the DataFrame by the `age` column in descending order. The `ascending=False` argument specifies the sort order.\n",
    "\n",
    "- The DataFrame `sorted_df` is now sorted by age, with the oldest employees first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Data\n",
    "\n",
    "Aggregating data means summarizing the data using operations like sum, average, count, etc. Aggregation can be done directly in SQL or using Pandas after loading the data.\n",
    "\n",
    "- __Example: Aggregating with SQL Query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    department  avg_salary\n",
      "0  Engineering     63500.0\n",
      "1           HR     53000.0\n",
      "2    Marketing     58000.0\n",
      "3        Sales     71200.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Write an SQL query to calculate the average salary by department.\n",
    "query = 'SELECT department,  AVG(salary) as avg_salary FROM employee GROUP BY department'\n",
    "\n",
    "# Step 2: Execute the SQL query and load the aggregated data into a Pandas DataFrame.\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Step 3: Display the aggregated DataFrame.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Explanation:__\n",
    "\n",
    "- `AVG(salary) AS average_salary:` This calculates the average salary for each department.\n",
    "\n",
    "- `GROUP BY department:` This groups the data by the department column before applying the aggregation.\n",
    "\n",
    "- The resulting DataFrame df contains the average salary for each department.\n",
    "\n",
    "__Example: Aggregating with Pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    department  avg_salary\n",
      "0  Engineering     63500.0\n",
      "1           HR     53000.0\n",
      "2    Marketing     58000.0\n",
      "3        Sales     71200.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Assume 'df' is a DataFrame containing employees' data.\n",
    "\n",
    "# Step 2: Use Pandas' groupby() to group the data by department.\n",
    "# Then, use the mean() function to calculate the average salary for each group.\n",
    "aggregated_df = df.groupby('department')['avg_salary'].mean().reset_index()\n",
    "\n",
    "# Step 3: Display the aggregated DataFrame.\n",
    "print(aggregated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "\n",
    "    - `df.groupby('department')['salary'].mean():` This groups the DataFrame by the `department` column and calculates the mean salary for each group.\n",
    "\n",
    "    - `reset_index():` This resets the index of the resulting DataFrame, making `department` a column again.\n",
    "\n",
    "    - The DataFrame `aggregated_df` now contains the average salary for each `department`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Tables with Pandas\n",
    "\n",
    "Joining tables refers to combining data from multiple sources (tables) into a single DataFrame based on common columns. Pandas allows you to perform various types of joins (inner, left, right, outer) similar to SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inner Join\n",
    "\n",
    "An inner join returns only the rows with matching values in both tables.\n",
    "\n",
    "- __Example: Inner Join with SQL Query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name, department_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Write an SQL query to perform an inner join between employee and departments.\n",
    "query = '''\n",
    "SELECT employee.name, department.department_name\n",
    "FROM employee\n",
    "INNER JOIN department\n",
    "ON employee.department_id = department.department_id\n",
    "'''\n",
    "\n",
    "# Step 2: Execute the SQL query and load the joined data into a Pandas DataFrame.\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Step 3: Display the joined DataFrame.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "    - `INNER JOIN departments ON employees.department_id = departments.id:` This joins the employees table with the `departments` table where the `department_id` in `employees` matches the id in `departments`.\n",
    "\n",
    "    - The resulting DataFrame dd`f contains only the rows where there is a match between the two tables.\n",
    "    \n",
    "- __Example: Inner Join with Pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Assume 'employees_df' and 'departments_df' are DataFrames.\n",
    "\n",
    "# Step 2: Use Pandas' merge() to perform an inner join on the department_id and id columns.\n",
    "merged_df = pd.merge(employees_df, departments_df, left_on='department_id', right_on='id')\n",
    "\n",
    "# Step 3: Display the joined DataFrame.\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "    - `pd.merge(employees_df, departments_df, left_on='department_id', right_on='id'):` This merges `employees_df` and `departments_df` on the `department_id` column from `employees_df` and the id column from `departments_df`.\n",
    "    \n",
    "    - The resulting DataFrame merged_df contains only rows where there is a match between the two DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Left Join\n",
    "\n",
    "A left join returns all rows from the left table (first table) and the matching rows from the right table (second table). Non-matching rows from the right table will have NaN values.\n",
    "\n",
    "- __Example: Left Join with SQL Query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Write an SQL query to perform a left join between employees and departments.\n",
    "query = '''\n",
    "SELECT employees.name, departments.department\n",
    "FROM employees\n",
    "LEFT JOIN departments\n",
    "ON employees.department_id = departments.id\n",
    "'''\n",
    "\n",
    "# Step 2: Execute the SQL query and load the joined data into a Pandas DataFrame.\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Step 3: Display the joined DataFrame.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "    - `LEFT JOIN departments ON employees.department_id = departments.id:` This joins all rows from `employees` with matching rows from `departments`. If no match is found, the department column will have NaN values.\n",
    "    \n",
    "    - The resulting DataFrame `df` includes all employees, even if they do not belong to a department.\n",
    "- __Example: Left Join with Pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Assume 'employees_df' and 'departments_df' are DataFrames.\n",
    "\n",
    "# Step 2: Use Pandas' merge() to perform a left join on the department_id and id columns.\n",
    "merged_df = pd.merge(employees_df, departments_df, left_on='department_id', right_on='id', how='left')\n",
    "\n",
    "# Step 3: Display the joined DataFrame.\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explanation:\n",
    "    - `pd.merge(employees_df, departments_df, left_on='department_id', right_on='id', how='left'):` This merges `employees_df` and `departments_df` using a left join. All rows from `employees_df` are retained, and non-matching rows in `departments_df` result in NaN values.\n",
    "    \n",
    "    - The resulting DataFrame `merged_df` contains all employees, even those without a matching department."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Right Join\n",
    "\n",
    "A right join is the opposite of a left join, returning all rows from the right table and matching rows from the left table. Non-matching rows from the left table will have NaN values.\n",
    "\n",
    "- __Example: Right Join with SQL Query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Write an SQL query to perform a right join between employees and departments.\n",
    "query = '''\n",
    "SELECT employees.name, departments.department\n",
    "FROM employees\n",
    "RIGHT JOIN departments\n",
    "ON employees.department_id = departments.id\n",
    "'''\n",
    "\n",
    "# Step 2: Execute the SQL query and load the joined data into a Pandas DataFrame.\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Step 3: Display the joined DataFrame.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "    - `RIGHT JOIN departments ON employees.department_id = departments.id:` This joins all rows from `departments` with matching rows from `employees`. If no match is found, the `name` column will have NaN values.\n",
    "\n",
    "    - The resulting DataFrame `df` includes all departments, even if no employees belong to them.\n",
    "\n",
    "- __Example: Right Join with Pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Assume 'employees_df' and 'departments_df' are DataFrames.\n",
    "\n",
    "# Step 2: Use Pandas' merge() to perform a right join on the department_id and id columns.\n",
    "merged_df = pd.merge(employees_df, departments_df, left_on='department_id', right_on='id', how='right')\n",
    "\n",
    "# Step 3: Display the joined DataFrame.\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "    - `pd.merge(employees_df, departments_df, left_on='department_id', right_on='id', how='right'):` This merges `employees_df` and `departments_df` using a right join. All rows from `departments_df` are retained, and non-matching rows in `employees_df` result in NaN values.\n",
    "    \n",
    "    - The resulting DataFrame `merged_df` contains all `departments`, even if they have no associated employees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Outer Join\n",
    "An outer join returns all rows from both tables, with NaN values for non-matching rows in either table.\n",
    "\n",
    "- __Example: Outer Join with SQL Query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Write an SQL query to perform a full outer join between employees and departments.\n",
    "# Note: Some SQL databases use \"FULL JOIN\" or \"FULL OUTER JOIN\".\n",
    "query = '''\n",
    "SELECT employees.name, departments.department\n",
    "FROM employees\n",
    "FULL OUTER JOIN departments\n",
    "ON employees.department_id = departments.id\n",
    "'''\n",
    "\n",
    "# Step 2: Execute the SQL query and load the joined data into a Pandas DataFrame.\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Step 3: Display the joined DataFrame.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "\n",
    "    - `FULL OUTER JOIN departments ON employees.department_id = departments.id:` This returns all rows from both `employees` and `departments`, with NaN values where no match is found. \n",
    "\n",
    "    - The resulting DataFrame `df` includes all employees and `departments`, even those without a match.\n",
    "\n",
    "__Example: Outer Join with Pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Assume 'employees_df' and 'departments_df' are DataFrames.\n",
    "\n",
    "# Step 2: Use Pandas' merge() to perform an outer join on the department_id and id columns.\n",
    "merged_df = pd.merge(employees_df, departments_df, left_on='department_id', right_on='id', how='outer')\n",
    "\n",
    "# Step 3: Display the joined DataFrame.\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Explanation:__\n",
    "\n",
    "    - `pd.merge(employees_df, departments_df, left_on='department_id', right_on='id', how='outer'):` This merges `employees_df` and `departments_df` using an outer join. All rows from both DataFrames are retained, with NaN values where no match is found.\n",
    "\n",
    "    - The resulting DataFrame `merged_df` contains all employees and departments, even those without a match.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application\n",
    "\n",
    "## Connecting to a Database using SQLAlchemy\n",
    "\n",
    "SQLAlchemy is a powerful toolkit and Object Relational Mapper (ORM) for Python, allowing you to connect to various databases seamlessly. The `create_engine` function in SQLAlchemy is used to establish a connection to your database, whether it’s SQLite, MySQL, PostgreSQL, or any other supported database system. Here’s how to use it:\n",
    "\n",
    "- Creating a Connection String:The connection string defines how to connect to your database, including the database dialect (like `sqlite`, `mysql`, etc.), driver, username, password, host, port, and database name. The format is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect+driver://username:password@host:port/database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to connect to an SQLite database, the connection string might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# SQLite connection string\n",
    "\n",
    "engine = create_engine('sqlite:///mydatabase.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, `sqlite:///mydatabase.db` indicates that you are connecting to an SQLite database named `mydatabase.db`. If the file does not exist, SQLite will create it.\n",
    "\n",
    "- __Handling Authentication:__\n",
    "When connecting to more complex databases like MySQL or PostgreSQL, you’ll often need to include authentication details in the connection string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+pymysql://username:password@localhost/mydatabase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "- mysql+pymysql specifies the MySQL dialect and the pymysql driver.\n",
    "\n",
    "- username and password are your database credentials.\n",
    "\n",
    "- localhost is the database host (can be an IP address or domain name).\n",
    "\n",
    "- mydatabase is the name of the database you want to connect to.\n",
    "\n",
    "__Example of Establishing a Connection:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Example connection to a MySQL database \n",
    "engine = create_engine('mysql+pymysql://root:1507@localhost/purchase')\n",
    "\n",
    "# Connect to database\n",
    "connection = engine.connect()\n",
    "\n",
    "print(\"Connection successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code connects to the MySQL database and prints a confirmation message. Once connected, you can execute queries and interact with the database through this connection.\n",
    "\n",
    "# Querying Data from SQLite\n",
    "Explanation:\n",
    "\n",
    "Once you’ve established a connection to your database using SQLAlchemy, the next step is to execute SQL queries to extract data. Here’s how you can query data from an SQLite database and load it into a Pandas DataFrame:\n",
    "\n",
    "Executing SQL Queries:You can execute SQL queries directly through the connection object. For example, to select all records from a table called `employees`, you might use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine \n",
    "import pandas as pd \n",
    "\n",
    "# Connect to SQLite database \n",
    "engine = create_engine('sqlite:///mydatabase.db')\n",
    "\n",
    "# SQL query\n",
    "query = \"SELECT * FROM emoployee\"\n",
    "\n",
    "# Execute the query and load data into a dataframe\n",
    "df = pd.read_sql(query, con = engine)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In this example:__\n",
    "\n",
    "- The SQL query \"SELECT * FROM employees\" is executed to retrieve all records from the employees table.\n",
    "\n",
    "- The pd.read_sql function reads the result of the query and loads it directly into a Pandas DataFrame.\n",
    "\n",
    "__Filtering Data with SQL Queries:__\n",
    "\n",
    "You can also write more complex SQL queries to filter, sort, or aggregate data before loading it into Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT name, age FROM employees WHERE age > 30 ORDER BY age DESC\"\n",
    "df = pd.read_sql(query, con=connection)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query retrieves the name and age columns from the employees table for employees older than 30, sorted by age in descending order.\n",
    "\n",
    "__Closing the Connection:__\n",
    "\n",
    "After you’re done with the database operations, it’s good practice to close the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Data Analysis with Pandas\n",
    "\n",
    "Once the data is loaded into a Pandas DataFrame, you can perform various data analysis tasks. Pandas offers a wide range of functions for data cleaning, transformation, and visualization. Here’s how to analyze the queried data:\n",
    "\n",
    "- __Data Cleaning__:Before performing analysis, you might need to clean the data by handling missing values, converting data types, or removing duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values with a default value\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Transformation:__\n",
    "You can transform the data by creating new columns, renaming columns, or filtering rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column based on existing data\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 18, 35, 60, 100], labels=['Child', 'Young Adult', 'Adult', 'Senior'])\n",
    "\n",
    "# Rename columns\n",
    "df.rename(columns={'name': 'employee_name'}, inplace=True)\n",
    "\n",
    "# Filter rows\n",
    "adults = df[df['age_group'] == 'Adult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Visualization:__\n",
    "Visualization is crucial for understanding trends and patterns in the data. You can create various plots using Pandas and Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of ages\n",
    "df['age'].plot(kind='hist', bins=10, title='Age Distribution')\n",
    "\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a histogram of the age column, allowing you to visualize the distribution of ages within your dataset.\n",
    "\n",
    "- __Aggregation and Grouping:__\n",
    "You can aggregate data to summarize information, such as calculating averages, sums, or counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by age group and calculate the average age\n",
    "age_summary = df.groupby('age_group')['age'].mean()\n",
    "\n",
    "print(age_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example groups the data by age_group and calculates the mean age for each group.\n",
    "\n",
    "By mastering these practical applications—connecting to databases using SQLAlchemy, querying data from SQLite, and performing data analysis with Pandas—you can efficiently manage and analyze large datasets, turning raw data into actionable insight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
